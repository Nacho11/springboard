{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning For Recommendation Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('product_review_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_knn = dataset.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId       71894\n",
      "productId     5198\n",
      "rating           4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Removing all users who have not provided more than 1 rating\n",
    "filtered_df = dataset_for_knn.groupby('userId').filter(lambda x : len(x) > 1)\n",
    "n_users = filtered_df.nunique()[0]\n",
    "n_items = filtered_df.nunique()[1]\n",
    "print(filtered_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7eff28ecb490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_df = filtered_df.drop(filtered_df.query('rating == 5').sample(frac=0.4).index)\n",
    "filtered_df['rating'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129909, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Dot\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from keras.layers import Concatenate, Dense, Dropout\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Add, Lambda, Activation, Reshape, Concatenate, Dense\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ten_predicted(model, user, items):\n",
    "    predictions = model.predict([np.array([user]*len(items)), items])\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['ratings'])\n",
    "    item_id_df = pd.DataFrame(item_encoding, columns = ['itemId'])\n",
    "    item_id_df['ratings'] = predictions_df['ratings']\n",
    "    top_10 = item_id_df.sort_values(by = ['ratings'], ascending=False)[:10]\n",
    "    return top_10['itemId'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ten_actual(df, user):\n",
    "    return df[df['userId'] == user].sort_values(by = ['rating'], ascending=False)[:100]['productId'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_enc = LabelEncoder()\n",
    "filtered_df['userId'] = user_enc.fit_transform(filtered_df['userId'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_enc = LabelEncoder()\n",
    "filtered_df['productId'] = item_enc.fit_transform(filtered_df['productId'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_encoding = filtered_df['productId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoding = filtered_df['userId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 4904, 4900, 4901])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28820, 21466, 33571, ..., 63481, 38099, 53404])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('item_encoder.npy', item_enc.classes_)\n",
    "output = open('item_encoder.pkl', 'wb')\n",
    "pickle.dump(item_enc, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('user_encoder.npy', user_enc.classes_)\n",
    "output = open('user_encoder.pkl', 'wb')\n",
    "pickle.dump(user_enc, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([filtered_df['userId'], filtered_df['productId']]).T\n",
    "y = np.array(filtered_df['rating']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116918, 2), (12991, 2), (116918,), (12991,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer:\n",
    "    def __init__(self, n_items, n_factors):\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = Embedding(self.n_items, self.n_factors, embeddings_initializer='he_normal',\n",
    "                      embeddings_regularizer=l2(1e-6))(x)\n",
    "        x = Reshape((self.n_factors,))(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecommenderNet(n_users, n_movies, n_factors, min_rating, max_rating):\n",
    "    user = Input(shape=(1,))\n",
    "    u = EmbeddingLayer(n_users, n_factors)(user)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
    "    \n",
    "    x = Concatenate()([u, m])\n",
    "    x = Dropout(0.05)(x)\n",
    "    \n",
    "    x = Dense(10, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1827/1827 [==============================] - 34s 19ms/step - loss: 1.1637 - val_loss: 0.5894\n",
      "Epoch 2/20\n",
      "1827/1827 [==============================] - 35s 19ms/step - loss: 0.4176 - val_loss: 0.6044\n",
      "Epoch 3/20\n",
      "1827/1827 [==============================] - 35s 19ms/step - loss: 0.3202 - val_loss: 0.6238\n",
      "Epoch 4/20\n",
      "1827/1827 [==============================] - 35s 19ms/step - loss: 0.2759 - val_loss: 0.6489\n",
      "Epoch 5/20\n",
      "1827/1827 [==============================] - 35s 19ms/step - loss: 0.2560 - val_loss: 0.6718\n",
      "Epoch 6/20\n",
      "1827/1827 [==============================] - 35s 19ms/step - loss: 0.2470 - val_loss: 0.6855\n",
      "Epoch 7/20\n",
      "1827/1827 [==============================] - 37s 20ms/step - loss: 0.2419 - val_loss: 0.6841\n",
      "Epoch 8/20\n",
      "1827/1827 [==============================] - 38s 21ms/step - loss: 0.2335 - val_loss: 0.6785\n",
      "Epoch 9/20\n",
      "1827/1827 [==============================] - 52s 28ms/step - loss: 0.2333 - val_loss: 0.6838\n",
      "Epoch 10/20\n",
      "1827/1827 [==============================] - 53s 29ms/step - loss: 0.2338 - val_loss: 0.6856\n",
      "Epoch 11/20\n",
      "1827/1827 [==============================] - 39s 21ms/step - loss: 0.2331 - val_loss: 0.6795\n",
      "Epoch 12/20\n",
      "1827/1827 [==============================] - 37s 20ms/step - loss: 0.2281 - val_loss: 0.6803\n",
      "Epoch 13/20\n",
      "1827/1827 [==============================] - 37s 20ms/step - loss: 0.2280 - val_loss: 0.6868\n",
      "Epoch 14/20\n",
      "1827/1827 [==============================] - 36s 20ms/step - loss: 0.2297 - val_loss: 0.6889\n",
      "Epoch 15/20\n",
      "1827/1827 [==============================] - 36s 20ms/step - loss: 0.2296 - val_loss: 0.6818\n",
      "Epoch 16/20\n",
      "1827/1827 [==============================] - 37s 20ms/step - loss: 0.2240 - val_loss: 0.6906\n",
      "Epoch 17/20\n",
      "1827/1827 [==============================] - 38s 21ms/step - loss: 0.2287 - val_loss: 0.6789\n",
      "Epoch 18/20\n",
      "1827/1827 [==============================] - 38s 21ms/step - loss: 0.2237 - val_loss: 0.6768\n",
      "Epoch 19/20\n",
      "1827/1827 [==============================] - 38s 21ms/step - loss: 0.2232 - val_loss: 0.6916\n",
      "Epoch 20/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2202 - val_loss: 0.6871\n"
     ]
    }
   ],
   "source": [
    "model = RecommenderNet(n_users, n_items, 50, 1, 5)\n",
    "history = model.fit(x=X_train_array, y=y_train, batch_size=64, epochs=20,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.629820645061966"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.round(model.predict(X_test_array)).astype('int')\n",
    "accuracy_score(np.round(y_test).astype('int'), np.round(prediction).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2009, 4130, 3317, 4181, 4692, 4386, 1825, 4096, 4293, 4615])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_predicted(model, 3, item_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralCollabrativeFiltering(n_users, n_items, n_factors, min_rating, max_rating):\n",
    "    \n",
    "    item_input = Input(shape=[1], name='Item')\n",
    "    \n",
    "    item_embedding_mf = Embedding(n_items, n_factors, embeddings_regularizer=l2(1e-6),\n",
    "                                  embeddings_initializer='he_normal',\n",
    "                                  name='ItemEmbeddingMF')(item_input)\n",
    "    item_vec_mf = Flatten(name='FlattenItemMF')(item_embedding_mf)\n",
    "    \n",
    "    \n",
    "    item_embedding_mlp = Embedding(n_items, n_factors, embeddings_regularizer=l2(1e-6),\n",
    "                                embeddings_initializer='he_normal',\n",
    "                               name='ItemEmbeddingMLP')(item_input)\n",
    "    item_vec_mlp = Flatten(name='FlattenItemMLP')(item_embedding_mlp)\n",
    "    \n",
    "    user_input = Input(shape=[1], name='User')\n",
    "    \n",
    "    user_embedding_mf = Embedding(n_users, n_factors, embeddings_regularizer=l2(1e-6), \n",
    "                                embeddings_initializer='he_normal',\n",
    "                               name='UserEmbeddingMF')(user_input)\n",
    "    user_vec_mf = Flatten(name='FlattenUserMF')(user_embedding_mf)\n",
    "    \n",
    "    user_embedding_mlp = Embedding(n_users, n_factors, embeddings_regularizer=l2(1e-6),\n",
    "                               embeddings_initializer='he_normal',\n",
    "                               name='UserEmbeddingMLP')(user_input)\n",
    "    user_vec_mlp = Flatten(name='FlattenUserMLP')(user_embedding_mlp)\n",
    "    \n",
    "    DotProductMF = Dot(axes=1, name='DotProductMF')([item_vec_mf, user_vec_mf])\n",
    "    \n",
    "    ConcatMLP = Concatenate(name='ConcatMLP')([item_vec_mlp, user_vec_mlp])\n",
    "    \n",
    "    Dense_1 = Dense(50, name=\"Dense1\")(ConcatMLP)\n",
    "    Dense_2 = Dense(20, name=\"Dense2\")(Dense_1)\n",
    "\n",
    "    Concat = Concatenate(name=\"ConcatAll\")([DotProductMF, Dense_2])\n",
    "    \n",
    "    Pred = Dense(1, name=\"Pred\")(Concat)\n",
    "    \n",
    "    item_bias = Embedding(n_items, 1, embeddings_regularizer=l2(1e-5), name='ItemBias')(item_input)\n",
    "    item_bias_vec = Flatten(name='FlattenItemBiasE')(item_bias)\n",
    "\n",
    "    user_bias = Embedding(n_users, 1, embeddings_regularizer=l2(1e-5), name='UserBias')(user_input)\n",
    "    user_bias_vec = Flatten(name='FlattenUserBiasE')(user_bias)\n",
    "\n",
    "    PredAddBias = Add(name=\"AddBias\")([Pred, item_bias_vec, user_bias_vec])\n",
    "    \n",
    "    y = Activation('sigmoid')(PredAddBias)\n",
    "    rating_output = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(y)\n",
    "    \n",
    "    model = Model([user_input, item_input], rating_output)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 40\n",
    "model = NeuralCollabrativeFiltering(n_users, n_items, n_factors, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ItemEmbeddingMLP (Embedding)    (None, 1, 40)        207920      Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "UserEmbeddingMLP (Embedding)    (None, 1, 40)        2875760     User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenItemMLP (Flatten)        (None, 40)           0           ItemEmbeddingMLP[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUserMLP (Flatten)        (None, 40)           0           UserEmbeddingMLP[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ItemEmbeddingMF (Embedding)     (None, 1, 40)        207920      Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "UserEmbeddingMF (Embedding)     (None, 1, 40)        2875760     User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "ConcatMLP (Concatenate)         (None, 80)           0           FlattenItemMLP[0][0]             \n",
      "                                                                 FlattenUserMLP[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "FlattenItemMF (Flatten)         (None, 40)           0           ItemEmbeddingMF[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUserMF (Flatten)         (None, 40)           0           UserEmbeddingMF[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 50)           4050        ConcatMLP[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "DotProductMF (Dot)              (None, 1)            0           FlattenItemMF[0][0]              \n",
      "                                                                 FlattenUserMF[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 20)           1020        Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "ConcatAll (Concatenate)         (None, 21)           0           DotProductMF[0][0]               \n",
      "                                                                 Dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "ItemBias (Embedding)            (None, 1, 1)         5198        Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "UserBias (Embedding)            (None, 1, 1)         71894       User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Pred (Dense)                    (None, 1)            22          ConcatAll[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FlattenItemBiasE (Flatten)      (None, 1)            0           ItemBias[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUserBiasE (Flatten)      (None, 1)            0           UserBias[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "AddBias (Add)                   (None, 1)            0           Pred[0][0]                       \n",
      "                                                                 FlattenItemBiasE[0][0]           \n",
      "                                                                 FlattenUserBiasE[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1)            0           AddBias[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,249,544\n",
      "Trainable params: 6,249,544\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1827/1827 [==============================] - 88s 47ms/step - loss: 0.7611 - val_loss: 0.5599\n",
      "Epoch 2/20\n",
      "1827/1827 [==============================] - 84s 46ms/step - loss: 0.3285 - val_loss: 0.5640\n",
      "Epoch 3/20\n",
      "1827/1827 [==============================] - 85s 46ms/step - loss: 0.1497 - val_loss: 0.5817\n",
      "Epoch 4/20\n",
      "1827/1827 [==============================] - 85s 47ms/step - loss: 0.0900 - val_loss: 0.5753\n",
      "Epoch 5/20\n",
      "1827/1827 [==============================] - 84s 46ms/step - loss: 0.0811 - val_loss: 0.5665\n",
      "Epoch 6/20\n",
      "1827/1827 [==============================] - 81s 44ms/step - loss: 0.0753 - val_loss: 0.5689\n",
      "Epoch 7/20\n",
      "1827/1827 [==============================] - 80s 44ms/step - loss: 0.0718 - val_loss: 0.5642\n",
      "Epoch 8/20\n",
      "1827/1827 [==============================] - 82s 45ms/step - loss: 0.0705 - val_loss: 0.5641\n",
      "Epoch 9/20\n",
      "1827/1827 [==============================] - 90s 49ms/step - loss: 0.0670 - val_loss: 0.5578\n",
      "Epoch 10/20\n",
      "1827/1827 [==============================] - 90s 49ms/step - loss: 0.0623 - val_loss: 0.5634\n",
      "Epoch 11/20\n",
      "1827/1827 [==============================] - 89s 49ms/step - loss: 0.0602 - val_loss: 0.5647\n",
      "Epoch 12/20\n",
      "1827/1827 [==============================] - 89s 49ms/step - loss: 0.0564 - val_loss: 0.5646\n",
      "Epoch 13/20\n",
      "1827/1827 [==============================] - 90s 49ms/step - loss: 0.0545 - val_loss: 0.5700\n",
      "Epoch 14/20\n",
      "1827/1827 [==============================] - 86s 47ms/step - loss: 0.0535 - val_loss: 0.5677\n",
      "Epoch 15/20\n",
      "1827/1827 [==============================] - 86s 47ms/step - loss: 0.0510 - val_loss: 0.5736\n",
      "Epoch 16/20\n",
      "1827/1827 [==============================] - 87s 48ms/step - loss: 0.0491 - val_loss: 0.5759\n",
      "Epoch 17/20\n",
      "1827/1827 [==============================] - 88s 48ms/step - loss: 0.0477 - val_loss: 0.5768\n",
      "Epoch 18/20\n",
      "1827/1827 [==============================] - 84s 46ms/step - loss: 0.0474 - val_loss: 0.5791\n",
      "Epoch 19/20\n",
      "1827/1827 [==============================] - 83s 45ms/step - loss: 0.0457 - val_loss: 0.5830\n",
      "Epoch 20/20\n",
      "1827/1827 [==============================] - 83s 46ms/step - loss: 0.0456 - val_loss: 0.5874\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_array, y=y_train, batch_size=64, epochs=20,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074205218997768"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.round(model.predict(X_test_array)).astype('int')\n",
    "accuracy_score(np.round(y_test).astype('int'), np.round(prediction).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 311, 2785, 3317, 3116,  441, 1825,  963, 3147,  684, 4333])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_predicted(model, 3, item_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixFactorization(n_users, n_items, n_factors, min_rating, max_rating):\n",
    "    \n",
    "    item_input = Input(shape=[1], name='Item')\n",
    "    item_embedding = Embedding(n_items, n_factors, embeddings_regularizer=l2(1e-6),\n",
    "                               embeddings_initializer='glorot_normal',\n",
    "                               name='ItemEmbedding')(item_input)\n",
    "    item_vec = Flatten(name='FlattenItemE')(item_embedding)\n",
    "    \n",
    "    item_bias = Embedding(n_items, 1, embeddings_regularizer=l2(1e-6), \n",
    "                          embeddings_initializer='glorot_normal',\n",
    "                          name='ItemBias')(item_input)\n",
    "    item_bias_vec = Flatten(name='FlattenItemBiasE')(item_bias)\n",
    "\n",
    "    user_input = Input(shape=[1], name='User')\n",
    "    user_embedding = Embedding(n_users, n_factors, embeddings_regularizer=l2(1e-6),\n",
    "                               embeddings_initializer='glorot_normal',\n",
    "                               name='UserEmbedding')(user_input)\n",
    "    user_vec = Flatten(name='FlattenUserE')(user_embedding)\n",
    "    \n",
    "    user_bias = Embedding(n_users, 1, embeddings_regularizer=l2(1e-6), \n",
    "                        embeddings_initializer='glorot_normal',\n",
    "                          name='UserBias')(user_input)\n",
    "    user_bias_vec = Flatten(name='FlattenUserBiasE')(user_bias)\n",
    "\n",
    "    Concat = Concatenate(name='Concat')([item_vec, user_vec])\n",
    "    ConcatDrop = Dropout(0.5)(Concat)\n",
    "\n",
    "    kernel_initializer='he_normal'\n",
    "    \n",
    "    Dense_1 = Dense(10, kernel_initializer='glorot_normal', name=\"Dense1\")(ConcatDrop)\n",
    "    Dense_1_Drop = Dropout(0.5)(Dense_1)\n",
    "    Dense_2 = Dense(1, kernel_initializer='glorot_normal', name=\"Dense2\")(Dense_1_Drop)\n",
    "\n",
    "    \n",
    "    AddBias = Add(name=\"AddBias\")([Dense_2, item_bias_vec, user_bias_vec])\n",
    "    \n",
    "    y = Activation('sigmoid')(AddBias)\n",
    "    rating_output = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(y)\n",
    "    \n",
    "    model = Model([user_input, item_input], rating_output)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 50\n",
    "model = MatrixFactorization(n_users, n_items, n_factors, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1827/1827 [==============================] - 66s 36ms/step - loss: 1.0063 - val_loss: 0.5849\n",
      "Epoch 2/20\n",
      "1827/1827 [==============================] - 63s 34ms/step - loss: 0.4443 - val_loss: 0.5811\n",
      "Epoch 3/20\n",
      "1827/1827 [==============================] - 61s 34ms/step - loss: 0.3319 - val_loss: 0.6018\n",
      "Epoch 4/20\n",
      "1827/1827 [==============================] - 61s 34ms/step - loss: 0.2936 - val_loss: 0.6180\n",
      "Epoch 5/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2805 - val_loss: 0.6277\n",
      "Epoch 6/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2662 - val_loss: 0.6386\n",
      "Epoch 7/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2641 - val_loss: 0.6384\n",
      "Epoch 8/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2612 - val_loss: 0.6463\n",
      "Epoch 9/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2611 - val_loss: 0.6484\n",
      "Epoch 10/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2561 - val_loss: 0.6515\n",
      "Epoch 11/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2588 - val_loss: 0.6510\n",
      "Epoch 12/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2540 - val_loss: 0.6425\n",
      "Epoch 13/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2545 - val_loss: 0.6450\n",
      "Epoch 14/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2515 - val_loss: 0.6470\n",
      "Epoch 15/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2503 - val_loss: 0.6427\n",
      "Epoch 16/20\n",
      "1827/1827 [==============================] - 63s 34ms/step - loss: 0.2535 - val_loss: 0.6533\n",
      "Epoch 17/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2536 - val_loss: 0.6482\n",
      "Epoch 18/20\n",
      "1827/1827 [==============================] - 61s 34ms/step - loss: 0.2500 - val_loss: 0.6481\n",
      "Epoch 19/20\n",
      "1827/1827 [==============================] - 61s 33ms/step - loss: 0.2538 - val_loss: 0.6425\n",
      "Epoch 20/20\n",
      "1827/1827 [==============================] - 62s 34ms/step - loss: 0.2512 - val_loss: 0.6544\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_array, y=y_train, batch_size=64, epochs=20,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6303594796397506"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.round(model.predict(X_test_array)).astype('int')\n",
    "accuracy_score(np.round(y_test).astype('int'), np.round(prediction).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: first_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('first_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3317,  311,  963, 2867, 4333, 4577, 4692, 4037,  315, 4130])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten_predicted(model, 3, item_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
